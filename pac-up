#!/usr/bin/env python

from __future__ import print_function

import os
import sys
import getopt
import re
import datetime
import time
import subprocess
import pipes
import md5
import csv

debug_level = 0
foreground = False
logfile = "%s/.pac-up" % (os.environ['HOME'])

def daemonize():
    pid = os.fork()
    if pid > 0:
        sys.exit(0)
    #os.chdir('/')
    os.setsid()
    os.umask(0)
    for fd in range(0, 1023):
        try:
            os.close(fd)
        except OSError:
            pass
    os.open('/dev/null', os.O_RDWR)
    os.dup2(0, 1)
    os.dup2(0, 2)
    pid = os.fork()
    if pid > 0:
        sys.exit(0)

def logx(level, msg):
    nowstr = datetime.datetime.now().ctime()
    if foreground:
        print("%s: %s: %s" % (nowstr, level, msg))
    else:
        f = open(logfile, "a")
        f.write("%s: %s: %s\n" % (nowstr, level, msg))
        f.close()

def logi(s):
    logx('i', s)

def loge(s):
    logx('e', s)

def md5_file(pathname):
    hasher = md5.new()
    f = open(pathname, "r")
    buf = f.read(64*1024)
    while len(buf) > 0:
        hasher.update(buf)
        buf = f.read(64*1024)
    return hasher.hexdigest()

def urlencode(s):
    s = s.replace(' ', '+')
    # RFC 1738 reserved characters: ";", "/", "?", ":", "@", "=" and "&"
    for c in (';', '/', '?', ':', '@', '=', '&'):
        x = "%%%02X" % ord(c)
        s = s.replace(c, x)
    return s

def make_query(m):
    q = ''
    for k, v in m.iteritems():
        if len(q) > 0:
            q += "&"
        q += "%s=%s" % (k, urlencode(str(v)))
    return q

def curl_file(rdir, path):
    #setup conf
    argv = [r'sed "/^--url/ s|\/\"|/{0}/\"|g" {1} > {2}.curlconf'.format(rdir, curl_conf_file, os.path.basename(path))]
    subprocess.call(argv, shell=True)

    #upload
    argv = [r'curl -K {0}.curlconf -T {1} 2>&1 | tee ~/.jenkins/curllogs/upload-{0}.log'.format(os.path.basename(path), path)]
    returncd = subprocess.call(argv, shell=True)
    logi('cURL return code {0} for {1}'.format(returnrc, path))

    #fix conf
    argv = [r'rm {0}.curlconf'.format(os.path.basename(path))]
    subprocess.call(argv, shell=True)

    return returncd

#get host file list and divvy up
def get_remote_list():
    #setup conf
    argv = [r'sed "/^--url/ s|\/\"|/{0}/\"|g" {1} > {2}'.format(remotedir, curl_conf_file, list_conf_file)]
    subprocess.call(argv, shell=True)
    argv = [r'sed -i "/verbose/d" {0}'.format(list_conf_file)]
    subprocess.call(argv, shell=True)
    argv = [r'sed -i "/write-out/d" {0}'.format(list_conf_file)]
    subprocess.call(argv, shell=True)

    #list the files
    argv = [r'curl -K {0} -X "MLSD"'.format(list_conf_file)]
    returncd = subprocess.Popen(argv, shell=True, stdout=subprocess.PIPE)
    #divvy up
    for line in iter(returncd.stdout.readline, ''):
        data, _, name = line.partition('; ')
        name = name[:-1]
        f_time = ''
        f_size = ''
        if name.endswith('delta'):
            logi('Found delta file: {0}'.format(name))
            delete_list.append(name)
            continue
        fields = data.split(';')
        for field in fields:
            field_name, _, field_value= field.partition('=')
            if field_name == 'size':
                f_size = field_value
            if field_name == 'modify':
                f_time = field_value
        if not f_time == '':
            if name.endswith('zip'):
                if int(f_size) < max_zip:
                    logi('Found a small zip: {0}'.format(name))
                    delete_list.append(name)
                else:
                    zip_list.append(f_time + '_' + f_size + '_' + name)
            if name.endswith('md5sum'):
                md5_list.append(f_time + '_' + f_size + '_' + name)

def put_file(rdir, path):

    returncd = curl_file(rdir, path)

    #update dl link if the upload worked
    if returncd == 0:
        logi('We should update hte DLM {0} {1}'.format(rdir, os.path.basename(path)))

        #TODO:check return value of the curl
        pass

def put_file_delta(rdir, newpath, oldpath):
    deltapath = newpath.replace('.zip', '.delta') # XXX

    newfile = os.path.basename(newpath)
    oldfile = os.path.basename(oldpath)
    deltafile = os.path.basename(deltapath)

    # Create delta file
    # XXX
    cmd = "rdiff signature \"%s\" | rdiff delta - \"%s\" \"%s\"" % (oldpath, newpath, deltapath)
    subprocess.call(cmd, shell=True)

    newmd5 = md5_file(newpath)
    oldmd5 = md5_file(oldpath)
    deltamd5 = md5_file(deltapath)

    curl_file(rdir, deltapath)

    # Construct remote file
    rdir2=rdir.replace('public_html/','')
    query = make_query( {
        'action'    : 'mkdelta',
        'basisfile' : "%s/%s" % (rdir2, oldfile),
        'deltafile' : "%s/%s" % (rdir2, deltafile),
        'outputfile': "%s/%s" % (rdir2, newfile),
        'basismd5'  : oldmd5,
        'deltamd5'  : deltamd5,
        'outputmd5' : newmd5 } )
    argv = ['/usr/bin/wget', '-q', '-O', '-',
        '--post-data=%s' % (query),
        'https://s.%s/uploads/devs/pacman/mkdelta.php' % (ftp_host)]
    child = subprocess.Popen(argv, stdin=None, stdout=subprocess.PIPE, stderr=None)
    out, err = child.communicate()
    rc = False
    if child.returncode == 0:
        for line in out.split("\n"):
            if line == 'mk-delta_result=ok':
                rc = True

    # we are done here, remove the deltafile
    ftp = ftplib.FTP(ftp_host, ftp_user, ftp_pass)
    ftp.cwd(remotedir)
    response = ftp.delete(deltafile)
    ftp.quit()

    return rc

optargs, argv = getopt.getopt(sys.argv[1:], 'df', ['debug', 'foreground'])
for k, v in optargs:
    if k in ('-d', '--debug'):
        debug_level += 1
    if k in ('-f', '--foreground'):
        foreground = True

if len(argv) != 3:
    print("Usage: pac-up remote-dir local-pathname host-file")
    sys.exit(1)

remotedir = argv[0]
newpath = argv[1]
u_host = argv[2]
newmd5 = newpath + '.md5sum'
max_zip = 185000000 # the trigger to indicate the zip is undersized and may be from a broken upload
max_n_zip = 10 #the maximun number of zip files allowed in a nightly folder
md5_list = []
zip_list = []
delete_list = []
newfile = os.path.basename(newpath)

#curl Config
curl_conf_file = '/home/build/.jenkins/curl{0}'.format(u_host)
list_conf_file = '{0}.{1}'.format(curl_conf_file, newfile)

#parse the host file
host_file = ('/home/build/.jenkins/%s' % (u_host))
lines = open( host_file, "r" ).readlines()
for line in lines:
    if re.search( "host", line ):
        title, ftp_host = line.split(' ', 1)
        ftp_host = ftp_host.rstrip('\n')
    if re.search( "user", line ):
        title, ftp_user = line.split(' ', 1)
        ftp_user = ftp_user.rstrip('\n')
    if re.search( "pass", line ):
        title, ftp_pass = line.split(' ', 1)
        ftp_pass = ftp_pass.rstrip('\n')

##-- clean deadwood from the host --##
make_lists = get_remote_list()
#add more garbage to delete list
if zip_list:
    zip_list = sorted(zip_list)
    #remove missmatched zip files
    garbage_list = []
    for z_file in zip_list:
        f_date, f_size, f_name = z_file.split("_", 2)
        if not any(f_name in z for z in md5_list):
            list_index = zip_list.index(z_file)
            garbage_list.append(list_index)
            logi('no mate for {0}'.format(z_file))
            delete_list.append(f_name)
    if garbage_list:
        garbage_list.sort(reverse=True)
        for i in garbage_list:
            zip_list.pop(i)
    #remove missmatched md5 files
    garbage_list = []
    for m_file in md5_list:
        f_date, f_size, f_name = m_file.split("_", 2)
        if not any(f_name[:7] in m for m in zip_list):
            list_index = md5_list.index(m_file)
            garbage_list.append(list_index)
            logi('no mate for {0}'.format(m_file))
            delete_list.append(f_name)
    if garbage_list:
        garbage_list.sort(reverse=True)
        for i in garbage_list:
            md5_list.pop(i)
    #remove excess
    if len(zip_list) > max_n_zip:
        excess = len(zip_list) - max_n_zip
        garbage = zip_list.pop(0)
        f_date, f_size, f_name = garbage.split("_", 2)
        logi('let us remove excess file {0}'.format(f_name))
        delete_list.append(f_name)
        delete_list.append(f_name + '.md5sum')

#delete remote files
if delete_list:
    for garbage in delete_list:
        logi('Removing obsolete file: {0}'.format(garbage))
        argv = [r'curl -K {0} -X "dele {1}"'.format(list_conf_file, garbage)]
        response = subprocess.call(argv, shell=True, stdout=subprocess.PIPE)

#cleanup
argv = [r'rm {0}'.format(list_conf_file)]
subprocess.call(argv, shell=True)
##-- deadwood cleaning done --##

if not os.path.exists(newpath):
    print("No such file %s" % (newpath))
    sys.exit(1)

if not foreground:
    daemonize()

logi("upload %s %s" % (remotedir, newpath))

m = re.search('\d{8}', newfile)
if m is None:
    logi("no date stamp found in file, fall back to normal upload")
    put_file(remotedir, newpath)
    put_file(remotedir, newmd5)
    sys.exit(0)

newdatestr = m.group(0)
newdate = datetime.date(int(newdatestr[0:4]), int(newdatestr[4:6]), int(newdatestr[6:8]))
olddate = newdate - datetime.timedelta(days=1)
olddatestr = "%04d%02d%02d" % (olddate.year, olddate.month, olddate.day)

oldpath = newpath.replace(newdatestr, olddatestr)

# check for oldfile on the bot
if not os.path.exists(oldpath):
    logi("yesterdays build not found on bot, fall back to normal upload")
    put_file(remotedir, newpath)
    put_file(remotedir, newmd5)
    sys.exit(0)

# check for oldfile on the server
if zip_list:
    roldfile = newfile.replace(newdatestr, olddatestr)
    if roldfile not in zip_list:
        logi("yesterdays build not found on server, fall back to normal upload")
        put_file(remotedir, newpath)
        put_file(remotedir, newmd5)
        sys.exit(0)

logi("attempt to put file via delta")
if not put_file_delta(remotedir, newpath, oldpath):
    logi("put file via delta failed, fall back to normal upload")
    put_file(remotedir, newpath)
    put_file(remotedir, newmd5)
    sys.exit(0)
